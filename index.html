<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ArtiFade</title>
  <!-- <link rel="icon" type="assets/png" href="" /> -->
  <!-- <link rel="canonical" href="" /> -->

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-71Y5XX2NRF"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());
        gtag('config', 'UA-97476543-1');
    </script>

  <!-- Meta tags -->
  <!-- TODO: META TAGS -->
  <!-- <meta name="keywords" content="BiGR, generative models, image generation, visual representations, representation learning">
  <meta property="og:site_name" content="BiGR">
  <meta property="og:url" content="">
  <meta property="og:title" content="BiGR: Harnessing Binary Latent Codes for Image Generation and Improved Visual Representation Capabilities">
  <meta name="description" content="A novel conditional image generation model that unifies generative and discriminative tasks effectively.">
  <meta property="og:description" content="A novel conditional image generation model that unifies generative and discriminative tasks effectively."> -->

  <!-- <meta property="og:image" content="">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">

  <meta property="og:image" content="">
  <meta property="og:image:width" content="300">
  <meta property="og:image:height" content="300"> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" type="text/css" href="./static/slick/slick.css" />
  <link rel="stylesheet" type="text/css" href="./static/slick/slick-theme.css" />
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script type="text/javascript" src="./static/slick/slick.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>
  <!-- Authors, institutions and links -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-3 publication-title">[CVPR 2025] ArtiFade: Learning to Generate High-quality Subject from Blemished Images
            </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://shuya-9.github.io/">Shuya Yang</a><sup>*</sup>,
              </span>
              <span class="author-block"></span>
                <a href="https://haoosz.github.io/">Shaozhe Hao</a><sup>*</sup>,
              </span>
              <span class="author-block"></span>
                <a href="https://yukangcao.github.io/">Yukang Cao</a><sup>&dagger;</sup>,
              </span>
              <span class="author-block">
                <a href="https://i.cs.hku.hk/~kykwong/">Kwan-Yee K. Wong</a><sup>&dagger;</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              The University of Hong Kong</span> &nbsp;
            </div>
            <div class="is-size-6 publication-authors">
              <span class="author-block">*Equal contribution &nbsp; &nbsp; &dagger;Corresponding authors</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="./asset/ArtiFade_CVPR_2025.pdf" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>PDF</span>
                  </a>
                </span>            
                <!-- arXiv Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2409.03745" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>

                <!-- Video Link. -->
                <!-- <span class="link-block">
                  <a href=""
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span> -->

                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/Shuya-9/ArtiFade"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Teaser -->
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div id="teaser" class="has-text-centered">
          <img style="width: 100%;" src="./asset/teaser.png" alt="ArtiFade teaser.">
        </div>

        <h2 class="subtitle has-text-centered">
          <p>
          We introduce ArtiFade, the first model to tackle blemished subject-driven generation by adapting vanilla subject-driven methods (e.g., Textual Inversion and DreamBooth) to effectively extract subject-specific information from blemished training data.
          </p>
        </h2>
      </div>
    </div>

  </section>

  <!-- Abstract. -->
  <!-- <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Advantages of <span class="method-name">BiGR</span></h2>
          <div class="content has-text-justified">
            <p>
              <ul>
                <li>
                  <strong>Uniformity</strong>: <span class="method-name">BiGR</span> is the first conditional image generation model that unifies generative and discriminative tasks within the same model.
                   By modeling compact binary latent codes, <span class="method-name">BiGR</span> delivers strong performance in both tasks compared to existing models.
                </li>
                <li>
                  <strong>Efficiency</strong>: <span class="method-name">BiGR</span> generates images at a low time cost, 
                  attributed to the small number of sampling steps required in the iterative unmasking process, while still maintaining high generation quality.
                </li>
                <li>
                  <strong>Flexibility</strong>: <span class="method-name">BiGR</span> can be flexibly employed for various vision applications, such as inpainting, outpainting, editing, interpolation, and enrichment in a zero-shot manner, 
                  without the need for task-specific structural changes or parameter fine-tuning.
                </li>
                <li>
                  <strong>Scalability</strong>: <span class="method-name">BiGR</span> demonstrates scalability in both generative and discriminative tasks, 
                  as evidenced by comprehensive evaluations of generation quality and linear-probe performance.
                </li>
                </ul>
                </p>
            </p>
          </div>
        </div>
      </div>
    </div>
  </section> -->

  <!-- Paper video. -->
  <!-- <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-12">
          <div class="content has-text-justified">
            <div class="columns is-centered has-text-centered">
              <div class="column is-four-fifths">
                <h2 class="title is-3">Video</h2>
                <div class="publication-video">
                  <iframe src="" frameborder="0"
                    allow="autoplay; encrypted-media" allowfullscreen></iframe>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section> -->

  <!-- Method explanation -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-12">
          <h2 class="title is-3">Method</h2>

          <div class="content has-text-justified">

            <div class="container" style="text-align: center;">
              <img width="100%" src="./asset/Flow.png"/>
              <br />
            </div>

            <p>
              Overview of ArtiFade. On the left, we present artifact rectification training, which involves an iterative process of calculating
              reconstruction loss between an unblemished image and the reconstruction of its blemished embedding. The right-hand side is the inference
              stage that tests ArtiFade on unseen blemished images. To avoid ambiguity, we (1) simplify the training of Textual Inversion into an input-output form, and (2) use “fine-tuning” and “inference” to respectively refer to the fine-tuning stage of ArtiFade and the use of ArtiFade for
              subject-driven generation.
            </p>

          </div>
        </div>
      </div>
    </div>
  </section>     


  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-12">
          <h2 class="title is-3">Results</h2>
          <!-- Quantitative results -->
          <h3 class="title is-4">Quantitative Comparison</h3>
          <div class="columns is-vcentered is-centered">
            <div class="column is-half has-text-centered" style="padding-right: -10px;">
              <img src="./asset/Quantitative-ID-TI.png" style="width: 100%;" />
            </div>
            <div class="column is-half has-text-centered" style="padding-left: -10px;">
              <img src="./asset/Quantitative-OOD-TI.png" style="width: 100%;" />
            </div>
          </div>
          <p style="text-align: center; margin-top: 16px;"></p>
            We conduct both in-distribution and out-of-distribution quantitative evaluations of our method and compare it to
            Textual Inversion with blemished embeddings.
            comparison to our model.
          </p>
          <!-- Generation examples - Textual Inversion -->
          <br>
          <br>
          <h3 class="title is-4">ArtiFade with Textual Inversion - Visible artifacts</h3>
          <div class="content has-text-justified">
            <div class="container" style="text-align: center;">
              <img width="80%" src="./asset/TI_watermark.png"/>
              <br />
            </div>
          </div>
          <!-- Generation examples - DreamBooth -->
          <br>
          <h3 class="title is-4">ArtiFade with DreamBooth - Visible artifacts</h3>
          <div class="content has-text-justified">
            <div class="container" style="text-align: center;">
              <img width="80%" src="./asset/DB_watermark.png"/>
              <br />
            </div>
          </div>
          <br>
          <h3 class="title is-4">ArtiFade with DreamBooth - Invisible artifacts</h3>
          <div class="content has-text-justified">
            <div class="container" style="text-align: center;">
              <img width="80%" src="./asset/DB_adversarial.png"/>
              <br />
            </div>
          </div>
          <!-- Applications -->
          <br>
          <h3 class="title is-4">Applications</h3>
          <div class="columns is-vcentered is-centered">
            <div class="column is-half has-text-centered" style="padding-right: -10px;">
              <img src="./asset/Application-glass.png" style="width: 90%;" />
            </div>
            <div class="column is-half has-text-centered" style="padding-left: -10px;">
              <img src="./asset/Application-sticker.png" style="width: 90%;" />
            </div>
          </div>
          <br>
          <h3 class="title is-4">More Qualitative Comparison</h3>
          <div class="content has-text-justified">
            <div class="container" style="text-align: center;">
              <img width="80%" src="./asset/watermark_faces.png"/>
              <br />
            </div>
          </div>
        </div>
      </div>
    </div>
    <br>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <p>If you find this project useful for your research, please cite the following:</p>
<pre align="left">
<code>@inproceedings{yang2025artifade,
  title={ArtiFade: Learning to Generate High-quality Subject from Blemished Images},
  author={Yang, Shuya and Hao, Shaozhe and Cao, Yukang and Wong, Kwan-Yee K},
  booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
  pages={13167--13177},
  year={2025}
}</code></pre>
    </div>
  </section>

</body>

</html>